```{python}
import polars as pl

df_raw = pl.read_csv("/Users/griffinsharps/Documents/Switchbox/smart-meter-analysis/ANONYMOUS_DATA_202301_60002-1102.csv")

df_raw.describe()

df_raw.schema

df_raw.shape

df_raw['ZIP_CODE'].n_unique()
df_raw['DELIVERY_SERVICE_CLASS'].n_unique()
df_raw['DELIVERY_SERVICE_NAME'].n_unique()
df_raw['ACCOUNT_IDENTIFIER'].n_unique()
```

1 zip code
1 class and name (do they ever differ?)
24 accounts in the csv

Wide to long
```{python}
from datetime import datetime, timedelta

interval_cols = [col for col in df_raw.columns if col.startswith('INTERVAL_HR')]

id_cols = [
  'ZIP_CODE',
  'DELIVERY_SERVICE_CLASS',
  'DELIVERY_SERVICE_NAME',
  'ACCOUNT_IDENTIFIER',
  'INTERVAL_READING_DATE',
  'INTERVAL_LENGTH',
  'TOTAL_REGISTERED_ENERGY',
  'PLC_VALUE',
  'NSPL_VALUE'
  ]

def transform_wide_to_long(df: pl.DataFrame) -> pl.DataFrame:

    long_df = df.select(id_cols + interval_cols).melt(
        id_vars=id_cols,
        value_vars=interval_cols,
        variable_name="interval_time",
        value_name="kwh",
    )

    long_df = long_df.with_columns([
        pl.col("interval_time")
          .str.extract(r"HR(\d{4})", group_index=1)
          .alias("time_str")
    ])

    long_df = (
        long_df
        .with_columns([
            pl.col("INTERVAL_READING_DATE")
              .str.strptime(pl.Date, format="%m/%d/%Y", strict=False)
              .alias("service_date"),

            pl.col("time_str").str.slice(0, 2).cast(pl.Int16).alias("hour_raw"),
            pl.col("time_str").str.slice(2, 2).cast(pl.Int16).alias("minute"),
        ])
        .with_columns([
            (pl.col("hour_raw") // 24).alias("days_offset"),
            (pl.col("hour_raw") % 24).alias("hour"),
        ])
        .with_columns([
            (
                pl.col("service_date").cast(pl.Datetime)
                + pl.duration(days=pl.col("days_offset"),
                              hours=pl.col("hour"),
                              minutes=pl.col("minute"))
            ).alias("datetime")
        ])
    )

    sort_keys = []
    if "ACCOUNT_IDENTIFIER" in long_df.columns:
        sort_keys.append("ACCOUNT_IDENTIFIER")
    sort_keys.append("datetime")
    long_df = long_df.sort(sort_keys)

    long_df = long_df.select([
        pl.col("ZIP_CODE").alias("zip_code"),
        pl.col("DELIVERY_SERVICE_CLASS").alias("delivery_service_class"),
        pl.col("DELIVERY_SERVICE_NAME").alias("delivery_service_name"),
        pl.col("ACCOUNT_IDENTIFIER").alias("account_identifier"),
        pl.col("datetime"),
        pl.col("kwh").cast(pl.Float64),
    ])

    return long_df

df_long = transform_wide_to_long(df_raw)
```

Adding in time features
```{python}
def create_time_features(df: pl.DataFrame) -> pl.DataFrame:

    # Better labels
    df = df.with_columns([
        pl.col('datetime').dt.hour().alias('hour'),
        pl.col('datetime').dt.weekday().alias('weekday'),
        pl.col('datetime').dt.day().alias('day'),
        (pl.col('datetime').dt.weekday() >= 5).alias('is_weekend')
    ])

    # Daily features per account
    daily_features = (
        df.group_by(['account_identifier', 'day'])
        .agg([
        pl.col('kwh').sum().alias('daily_total'),
        pl.col('kwh').mean().alias('daily_mean'),
        pl.col('kwh').std().alias('daily_std'),
        pl.col('kwh').max().alias('peak_demand'),
        pl.col('kwh').min().alias('base_load'),

        # Time-of-use calculations
        pl.col('kwh').filter((pl.col('hour') >= 6) & (pl.col('hour') < 9))
          .sum().alias('morning_usage'),
        pl.col('kwh').filter((pl.col('hour') >= 17) & (pl.col('hour') < 21))
          .sum().alias('evening_usage'),
        pl.col('kwh').filter((pl.col('hour') >= 22) | (pl.col('hour') < 6))
          .sum().alias('overnight_usage'),

        # Peak timing
        pl.col('hour').filter(pl.col('kwh') == pl.col('kwh').max())
          .first().alias('peak_hour')
    ]))

    # Monthly aggregation per account
    monthly_features = daily_features.group_by('account_identifier').agg([
        # Central tendency
        pl.col('daily_total').mean().alias('avg_daily_consumption'),
        pl.col('daily_total').std().alias('consumption_variability'),

        # Load shape metrics
        pl.col('peak_demand').mean().alias('avg_peak'),
        pl.col('base_load').mean().alias('avg_base_load'),
        (pl.col('daily_mean') / pl.col('peak_demand')).mean().alias('load_factor'),

        # Behavioral patterns
        pl.col('peak_hour').mode().first().alias('typical_peak_hour'),
        (pl.col('evening_usage') / pl.col('morning_usage')).mean()
          .alias('evening_morning_ratio')
    ])

    return monthly_features

df_long_features = create_time_features(df_long)
```
